---
---

@inproceedings{hu2024codefilling,
  title     = {Communication-Efficient Collaborative Perception via Information Filling with Codebook},
  author    = {Hu, Yue and Peng, Juntong and Liu, Sifei and Ge, Junhao and Liu, Si and Chen, Siheng},
  booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
  year      = {2024},
  abbr      = {CVPR},
  arxiv     = {2405.04966},
  preview   = {Codefilling.png},
  selected  = {true},
  abstract  = {We proposed a Communication-Efficient collaboration method, which enhances the tradeoff between performance and communication cost by optimizing information selection and representation.}
}

@article{peng2024gatar,
  title   = {Graph-based decentralized task allocation for multi-robot target localization},
  author  = {Peng, Juntong and Viswanath, Hrishikesh and Bera, Aniket},
  journal = {IEEE Robotics and Automation Letters},
  year    = {2024},
  abbr    = {RA-L},
  arxiv   = {2309.08896},
  preview = {gatar.png},
  selected = {true},
  abstract = {We proposed a graph neural network based method to dynamically allocate tasks to different robots. We utilized the comparative advantages of different robots to improve the overall performance of the system.}
}

@article{hu2025hycomm,
  title   = {Communication-Efficient Multi-Agent 3D Detection via Hybrid Collaboration},
  author  = {Hu, Yue and Peng, Juntong and Yang, Yunqiao and Qin, Xiaoqi and Feng, Zhiyong and Zhang, Wenjun and Chen, Siheng},
  year    = {2025},
  abbr    = {Preprint},
  arxiv   = {2508.07092},
  preview = {hycomm.png},
  selected = {true},
  abstract = {We utilized the confidence and uncertainty of single perception to guide the information sharing process, combining the benefits of both sparse and dense information form. Our method consumes far less communication resources than the previous SOTA.}
}

@inproceedings{wei2023coformer,
  title     = {Compatible transformer for irregularly sampled multivariate time series},
  author    = {Wei, Yuxi and Peng, Juntong and He, Tong and Xu, Chenxin and Zhang, Jian and Pan, Shirui and Chen, Siheng},
  booktitle = {Proceedings of the IEEE International Conference on Data Mining (ICDM)},
  year      = {2023},
  abbr      = {ICDM},
  arxiv     = {2310.11022},
  code      = {https://github.com/MediaBrain-SJTU/CoFormer},
  preview   = {coformer.png},
  selected  = {true},
  abstract  = {We proposed a transformer-based model to handle irregularly sampled multivariate time series. Our model is inspired by the correlation between multi-agent trajectories.}
}

@article{wang2025generative,
  title={Generative ai for autonomous driving: Frontiers and opportunities},
  author={Wang, Yuping and Xing, Shuo and Can, Cui and Li, Renjie and Hua, Hongyuan and Tian, Kexin and Mo, Zhaobin and Gao, Xiangbo and Wu, Keshu and Zhou, Sulong and others},
  journal={arXiv preprint arXiv:2505.08854},
  year={2025},
  abbr={Preprint},
  arxiv={2505.08854}
}

@article{zhou2025hierarchical,
  title={A hierarchical test platform for vision language model (vlm)-integrated real-world autonomous driving},
  author={Zhou, Yupeng and Cui, Can and Peng, Juntong and Yang, Zichong and Lu, Juanwu and Panchal, Jitesh and Yao, Bin and Wang, Ziran},
  journal={ACM Transactions on Internet of Things},
  year={2025},
  publisher={ACM New York, NY},
  abbr={ACM TIOT}
}

@article{cui2025vilad,
  title={Vilad: A large vision language diffusion framework for end-to-end autonomous driving},
  author={Cui, Can and Zhou, Yupeng and Peng, Juntong and Park, Sung-Yeon and Yang, Zichong and Sankaranarayanan, Prashanth and Zhang, Jiaru and Zhang, Ruqi and Wang, Ziran},
  journal={arXiv preprint arXiv:2508.12603},
  year={2025},
  abbr={Preprint},
  arxiv={2508.12603}
}

@article{zhao2025quantv2x,
  title={QuantV2X: A Fully Quantized Multi-Agent System for Cooperative Perception},
  author={Zhao, Seth Z and Zhang, Huizhi and Li, Zhaowei and Peng, Juntong and Chui, Anthony and Zhou, Zewei and Meng, Zonglin and Xiang, Hao and Huang, Zhiyu and Wang, Fujia and others},
  journal={arXiv preprint arXiv:2509.03704},
  year={2025},
  abbr={Preprint},
  arxiv={2509.03704}
}

@inproceedings{cui2025dasr,
  title={DASR: Distributed Adaptive Scene Recognition-A Multi-Agent Cloud-Edge Framework for Language-Guided Scene Detection},
  author={Cui, Can and Liu, Yongkang and Ucar, Seyhan and Peng, Juntong and Moradipari, Ahmadreza and Khabazi, Maryam and Wang, Ziran},
  booktitle={Proceedings of the 2025 Conference on Empirical Methods in Natural Language Processing: Industry Track},
  pages={850--858},
  year={2025},
  abbr={EMNLP}
}

@inproceedings{cui2025board,
  title={On-Board Vision-Language Models (VLMs) for Personalized Motion Control of Autonomous Vehicles},
  author={Cui, Can and Yang, Zichong and Zhou, Yupeng and Peng, Juntong and Park, Sung-Yeon and Zhang, Cong and Ma, Yunsheng and Cao, Xu and Ye, Wenqian and Feng, Yiheng and others},
  booktitle={2025 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)},
  pages={20349--20356},
  year={2025},
  organization={IEEE},
  abbr={IROS}
}

@article{pengfleetagent,
  title={FleetAgent: Natural Language Driving Explanation and Evaluation for Vehicle Teleoperation},
  author={Peng, Juntong and Chen, Qi and Qu, Deyuan and Shimizu, Takayuki and Chen, Yaobin and Wang, Ziran},
  year={2025},
  abbr={Preprint}
}
